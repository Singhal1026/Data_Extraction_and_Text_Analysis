{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5718bcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hello\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hello\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing required liberaries\n",
    "\n",
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec853a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL\n",
       "0  blackassign0001  https://insights.blackcoffer.com/rising-it-cit...\n",
       "1  blackassign0002  https://insights.blackcoffer.com/rising-it-cit...\n",
       "2  blackassign0003  https://insights.blackcoffer.com/internet-dema...\n",
       "3  blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...\n",
       "4  blackassign0005  https://insights.blackcoffer.com/ott-platform-..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('Input.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d084b27b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL with url_id - blackassign0036 not Found.\n",
      "URL with url_id - blackassign0049 not Found.\n"
     ]
    }
   ],
   "source": [
    "# Fetching data from URLs using BeautifulSoup\n",
    "# Storeing data in local directory named as \"Extracted_articles\"\n",
    "\n",
    "url_id_not_found = []\n",
    "\n",
    "for url, url_id in zip(data['URL'], data['URL_ID']):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status() \n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        \n",
    "        title = soup.find('title')\n",
    "        \n",
    "        post_content = soup.find('div', class_='td-post-content')\n",
    "        \n",
    "        content = ''\n",
    "        for i in post_content.find_all('p'):\n",
    "            content += ' ' + i.text\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'URL with url_id - {url_id} not Found.')\n",
    "        url_id_not_found.append(url_id)\n",
    "        \n",
    "    except AttributeError as e:\n",
    "        print(f'Attribute Error at URL with url_id - {url_id}')\n",
    "        url_id_not_found.append(url_id)\n",
    "        \n",
    "    else:\n",
    "        path = 'Extracted_articles'\n",
    "        if not os.path.exists(path):\n",
    "                !mkdir {path}\n",
    "        file_path = os.path.join(path, f'{url_id}.txt')\n",
    "        if not os.path.exists(file_path):\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(f'{title.text}\\n{content}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6df5313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all stopwords from StopWords Directory and storing it in common list\n",
    "\n",
    "stop_word = []\n",
    "for file in os.listdir('StopWords'):\n",
    "    with open(os.path.join('StopWords', file), 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            stop_word.append(line.strip().split('|')[0].strip().lower())\n",
    "stop_word = set(stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e251c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all positive and Negative words from MasterDictionary Directory and storing it in different list\n",
    "\n",
    "pos = []\n",
    "neg = []\n",
    "for file in os.listdir('MasterDictionary'):\n",
    "    with open(os.path.join('MasterDictionary', file), 'r') as f:\n",
    "        if file == 'positive-words.txt':\n",
    "            pos.extend(f.read().splitlines())\n",
    "        else:\n",
    "            neg.extend(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d8dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading scrapped data from local directory \n",
    "# Calculating few required Features\n",
    "\n",
    "articles = []\n",
    "tokenized_articles = []\n",
    "positive_score = []\n",
    "negative_score = []\n",
    "subjectivity_score = []\n",
    "polarity_score = []\n",
    "\n",
    "for file in os.listdir('Extracted_articles'):\n",
    "    with open(os.path.join('Extracted_articles', file), 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        articles.append(text)\n",
    "\n",
    "for text in articles:\n",
    "    words = nltk.word_tokenize(text)\n",
    "    tokenized_articles = [word for word in words if word.lower() not in stop_word]\n",
    "    p_count = sum([1 for word in tokenized_articles if word.lower() in pos])\n",
    "    n_count = sum([-1 for word in tokenized_articles if word.lower() in neg])*-1\n",
    "    subjectivity_score.append((p_count+n_count)/((len(tokenized_articles)) + 0.000001))\n",
    "    polarity_score.append((p_count-n_count)/((p_count+n_count) + 0.000001))\n",
    "    positive_score.append(p_count)\n",
    "    negative_score.append(n_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad94728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculatoin rest of the Features\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "exclude = string.punctuation\n",
    "\n",
    "\n",
    "def find(text):\n",
    "    # removing pucntuation\n",
    "    new_text = text.translate(str.maketrans('','',exclude))\n",
    "    \n",
    "    # word tokenizing\n",
    "    new_text = nltk.word_tokenize(new_text)\n",
    "    \n",
    "    # removing stop_words\n",
    "    words = [word for word in new_text if word.lower() not in stop_words]\n",
    "    total_words = len(words)                              # WORD COUNT\n",
    "    \n",
    "    # sentence tokenization\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    total_sentences = len(sentences)\n",
    "    avg_len_of_sen = total_words/total_sentences          # AVG SENTENCE LENGTH \n",
    "    \n",
    "    # Finding complex words count, syllable count, syllable word count\n",
    "    complex_words = 0                                     # COMPLEX WORD COUNT\n",
    "    syllable_cnt = 0\n",
    "    syllable_wrd_cnt = 0\n",
    "    for word in words:\n",
    "        if word.endswith('es'):\n",
    "            word = word[:-2]\n",
    "        if word.endswith('ed'):\n",
    "            word = word[:-2]\n",
    "        cnt = 0\n",
    "        flag = True\n",
    "        for i in word.lower():\n",
    "            if i in 'aeiou':\n",
    "                if flag:\n",
    "                    flag = False\n",
    "                    syllable_wrd_cnt+=1\n",
    "                syllable_cnt+=1\n",
    "                cnt+=1\n",
    "        if cnt>2:\n",
    "            complex_words+=1\n",
    "    \n",
    "    complex_words_in_pct = complex_words/total_words      # PERCENTAGE OF COMPLEX WORDS\n",
    "    fi = 0.4 * (avg_len_of_sen+complex_words_in_pct)      # FOG INDEX\n",
    "    avg_no_of_wrds_per_sen = total_words/total_sentences  # AVG NUMBER OF WORDS PER SENTENCE\n",
    "    syll_per_wrd = syllable_cnt/syllable_wrd_cnt          # SYLLABLE PER WORD\n",
    "    \n",
    "    total_char = sum([len(word) for word in words])\n",
    "    avg_wrd_len = total_char/total_words                  # AVG WORD LENGTH\n",
    "    \n",
    "    return [avg_len_of_sen, complex_words_in_pct, fi, avg_no_of_wrds_per_sen, complex_words, total_words, syll_per_wrd, avg_wrd_len]\n",
    "    \n",
    "def count_personal_pronouns(text):\n",
    "    # regex pattern to match personal pronouns\n",
    "    pattern = r'\\b(?:I|we|my|ours|us)\\b'\n",
    "\n",
    "    matches = re.findall(pattern, text, flags=re.IGNORECASE)\n",
    "\n",
    "    # exclude \"US\" as a country name\n",
    "    country_pattern = r'\\b(?:US)\\b'\n",
    "    country_matches = re.findall(country_pattern, text, flags=re.IGNORECASE)\n",
    "    for country_match in country_matches:\n",
    "        matches = [match for match in matches if match != 'US']\n",
    "\n",
    "    # Count the number of matches\n",
    "    count = len(matches)\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc7fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sentence_length = []\n",
    "Percentage_of_complex_words = []\n",
    "Fog_index = []\n",
    "Avg_no_of_words_per_sentence = []\n",
    "word_count = []\n",
    "complex_word_count = []\n",
    "personal_pronoun_count = []\n",
    "syllable_per_word = []\n",
    "avg_word_len = []\n",
    "\n",
    "# Function calling for each arcicle to calculate required features\n",
    "\n",
    "for text in articles:\n",
    "    lst = find(text)\n",
    "    avg_sentence_length.append(lst[0])\n",
    "    Percentage_of_complex_words.append(lst[1])\n",
    "    Fog_index.append(lst[2])\n",
    "    Avg_no_of_words_per_sentence.append(lst[3])\n",
    "    word_count.append(lst[5])\n",
    "    complex_word_count.append(lst[4])\n",
    "    syllable_per_word.append(lst[6])\n",
    "    avg_word_len.append(lst[7])\n",
    "    personal_pronoun_count.append(count_personal_pronouns(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed15115",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL  \\\n",
       "0  blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1  blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2  blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3  blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4  blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "\n",
       "   POSITIVE SCORE NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0             NaN            NaN             NaN                 NaN   \n",
       "1             NaN            NaN             NaN                 NaN   \n",
       "2             NaN            NaN             NaN                 NaN   \n",
       "3             NaN            NaN             NaN                 NaN   \n",
       "4             NaN                            NaN                 NaN   \n",
       "\n",
       "   AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                  NaN                          NaN        NaN   \n",
       "1                  NaN                          NaN        NaN   \n",
       "2                  NaN                          NaN        NaN   \n",
       "3                  NaN                          NaN        NaN   \n",
       "4                  NaN                          NaN        NaN   \n",
       "\n",
       "   AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                               NaN                 NaN         NaN   \n",
       "1                               NaN                 NaN         NaN   \n",
       "2                               NaN                 NaN         NaN   \n",
       "3                               NaN                 NaN         NaN   \n",
       "4                               NaN                 NaN         NaN   \n",
       "\n",
       "   SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                NaN                NaN              NaN  \n",
       "1                NaN                NaN              NaN  \n",
       "2                NaN                NaN              NaN  \n",
       "3                NaN                NaN              NaN  \n",
       "4                NaN                NaN              NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read \"Output Data Structure.xlsx\" File\n",
    "\n",
    "output = pd.read_excel('Output Data Structure.xlsx')\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9334261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows for which url not found\n",
    "\n",
    "output = output[~output['URL_ID'].isin(url_id_not_found)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d019026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing data with calculated data\n",
    "\n",
    "output['POSITIVE SCORE'] = positive_score\n",
    "output['NEGATIVE SCORE'] = negative_score\n",
    "output['POLARITY SCORE'] = polarity_score\n",
    "output['SUBJECTIVITY SCORE'] = subjectivity_score\n",
    "output['AVG SENTENCE LENGTH'] = avg_sentence_length\n",
    "output['PERCENTAGE OF COMPLEX WORDS'] = Percentage_of_complex_words\n",
    "output['FOG INDEX'] = Fog_index\n",
    "output['AVG NUMBER OF WORDS PER SENTENCE'] = Avg_no_of_words_per_sentence\n",
    "output['COMPLEX WORD COUNT'] = complex_word_count\n",
    "output['WORD COUNT'] = word_count\n",
    "output['SYLLABLE PER WORD'] = syllable_per_word\n",
    "output['PERSONAL PRONOUNS'] = personal_pronoun_count\n",
    "output['AVG WORD LENGTH'] = avg_word_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fdc7284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>7.560000</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>3.170032</td>\n",
       "      <td>7.560000</td>\n",
       "      <td>69</td>\n",
       "      <td>189</td>\n",
       "      <td>2.358696</td>\n",
       "      <td>4</td>\n",
       "      <td>6.253968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.093318</td>\n",
       "      <td>11.220779</td>\n",
       "      <td>0.474537</td>\n",
       "      <td>4.678127</td>\n",
       "      <td>11.220779</td>\n",
       "      <td>410</td>\n",
       "      <td>864</td>\n",
       "      <td>2.708785</td>\n",
       "      <td>4</td>\n",
       "      <td>7.120370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.077530</td>\n",
       "      <td>12.071429</td>\n",
       "      <td>0.572485</td>\n",
       "      <td>5.057566</td>\n",
       "      <td>12.071429</td>\n",
       "      <td>387</td>\n",
       "      <td>676</td>\n",
       "      <td>2.971386</td>\n",
       "      <td>13</td>\n",
       "      <td>8.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>37</td>\n",
       "      <td>74</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.148198</td>\n",
       "      <td>13.274510</td>\n",
       "      <td>0.548006</td>\n",
       "      <td>5.529006</td>\n",
       "      <td>13.274510</td>\n",
       "      <td>371</td>\n",
       "      <td>677</td>\n",
       "      <td>2.858877</td>\n",
       "      <td>5</td>\n",
       "      <td>7.741507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.062802</td>\n",
       "      <td>10.717949</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>4.466127</td>\n",
       "      <td>10.717949</td>\n",
       "      <td>187</td>\n",
       "      <td>418</td>\n",
       "      <td>2.639024</td>\n",
       "      <td>6</td>\n",
       "      <td>7.208134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>26</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>13.140000</td>\n",
       "      <td>0.435312</td>\n",
       "      <td>5.430125</td>\n",
       "      <td>13.140000</td>\n",
       "      <td>286</td>\n",
       "      <td>657</td>\n",
       "      <td>2.581903</td>\n",
       "      <td>4</td>\n",
       "      <td>6.989346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.228070</td>\n",
       "      <td>0.110251</td>\n",
       "      <td>14.105263</td>\n",
       "      <td>0.397388</td>\n",
       "      <td>5.801060</td>\n",
       "      <td>14.105263</td>\n",
       "      <td>213</td>\n",
       "      <td>536</td>\n",
       "      <td>2.378846</td>\n",
       "      <td>7</td>\n",
       "      <td>6.348881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>8.262178</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>46</td>\n",
       "      <td>101</td>\n",
       "      <td>2.280000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.663366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.046980</td>\n",
       "      <td>11.357143</td>\n",
       "      <td>0.317610</td>\n",
       "      <td>4.669901</td>\n",
       "      <td>11.357143</td>\n",
       "      <td>101</td>\n",
       "      <td>318</td>\n",
       "      <td>2.260726</td>\n",
       "      <td>4</td>\n",
       "      <td>6.028302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>29</td>\n",
       "      <td>55</td>\n",
       "      <td>-0.309524</td>\n",
       "      <td>0.154982</td>\n",
       "      <td>17.225806</td>\n",
       "      <td>0.417603</td>\n",
       "      <td>7.057364</td>\n",
       "      <td>17.225806</td>\n",
       "      <td>223</td>\n",
       "      <td>534</td>\n",
       "      <td>2.526000</td>\n",
       "      <td>3</td>\n",
       "      <td>6.762172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0                2               1        0.333333            0.015707   \n",
       "1               50              31        0.234568            0.093318   \n",
       "2               36              23        0.220339            0.077530   \n",
       "3               37              74       -0.333333            0.148198   \n",
       "4               18               8        0.384615            0.062802   \n",
       "..             ...             ...             ...                 ...   \n",
       "95              26              54       -0.350000            0.126582   \n",
       "96              22              35       -0.228070            0.110251   \n",
       "97               1               0        0.999999            0.009524   \n",
       "98              11               3        0.571429            0.046980   \n",
       "99              29              55       -0.309524            0.154982   \n",
       "\n",
       "    AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0              7.560000                     0.365079   3.170032   \n",
       "1             11.220779                     0.474537   4.678127   \n",
       "2             12.071429                     0.572485   5.057566   \n",
       "3             13.274510                     0.548006   5.529006   \n",
       "4             10.717949                     0.447368   4.466127   \n",
       "..                  ...                          ...        ...   \n",
       "95            13.140000                     0.435312   5.430125   \n",
       "96            14.105263                     0.397388   5.801060   \n",
       "97            20.200000                     0.455446   8.262178   \n",
       "98            11.357143                     0.317610   4.669901   \n",
       "99            17.225806                     0.417603   7.057364   \n",
       "\n",
       "    AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                           7.560000                  69         189   \n",
       "1                          11.220779                 410         864   \n",
       "2                          12.071429                 387         676   \n",
       "3                          13.274510                 371         677   \n",
       "4                          10.717949                 187         418   \n",
       "..                               ...                 ...         ...   \n",
       "95                         13.140000                 286         657   \n",
       "96                         14.105263                 213         536   \n",
       "97                         20.200000                  46         101   \n",
       "98                         11.357143                 101         318   \n",
       "99                         17.225806                 223         534   \n",
       "\n",
       "    SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0            2.358696                  4         6.253968  \n",
       "1            2.708785                  4         7.120370  \n",
       "2            2.971386                 13         8.038462  \n",
       "3            2.858877                  5         7.741507  \n",
       "4            2.639024                  6         7.208134  \n",
       "..                ...                ...              ...  \n",
       "95           2.581903                  4         6.989346  \n",
       "96           2.378846                  7         6.348881  \n",
       "97           2.280000                  0         6.663366  \n",
       "98           2.260726                  4         6.028302  \n",
       "99           2.526000                  3         6.762172  \n",
       "\n",
       "[98 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "753ef4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output as csv file\n",
    "\n",
    "output.to_csv('Output_Data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
